{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras_resnet.models import ResNet18\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tensorflow.image import resize\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mGpiFm8xY3IM",
    "outputId": "b9c4057c-9a37-4486-dab1-42e4b0bbe262"
   },
   "outputs": [],
   "source": [
    "# Initialize the MobileNetV2 model for feature extraction\n",
    "# Input shape is set to (96, 96, 3) for a balance between speed and feature quality\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "feature_extractor = MobileNetV2(weights='imagenet', include_top=False, pooling='avg', input_shape=(96, 96, 3))\n",
    "\n",
    "def extract_features(data):\n",
    "    \"\"\"\n",
    "    Extracts features from image data using the pre-trained MobileNetV2 model.\n",
    "\n",
    "    Args:\n",
    "        data (numpy.ndarray): Array of image data with shape (num_samples, 32, 32, 3).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Extracted feature vectors.\n",
    "    \"\"\"\n",
    "    # Resize images from (32, 32) to (96, 96) as MobileNetV2 expects larger images\n",
    "    resized_data = tf.image.resize(data, (96, 96)).numpy()\n",
    "    preprocessed_data = preprocess_input(resized_data)\n",
    "\n",
    "    # Extract features in batches to optimize memory usage\n",
    "    batch_size = 64\n",
    "    num_samples = preprocessed_data.shape[0]\n",
    "    features = []\n",
    "\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch = preprocessed_data[i:i+batch_size]\n",
    "        batch_features = feature_extractor.predict(batch, verbose=0)\n",
    "        # Normalize features for cosine similarity\n",
    "        batch_features = normalize(batch_features)\n",
    "        features.append(batch_features)\n",
    "\n",
    "    features = np.vstack(features)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Y114pUA6CN0y"
   },
   "outputs": [],
   "source": [
    "class LwPClassifier:\n",
    "    def __init__(self, num_classes, feature_dim):\n",
    "        \"\"\"\n",
    "        Initializes the LwP classifier with empty prototypes.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): Number of classes.\n",
    "            feature_dim (int): Dimensionality of feature vectors.\n",
    "        \"\"\"\n",
    "        self.num_classes = num_classes\n",
    "        self.feature_dim = feature_dim\n",
    "        # Initialize prototypes as zero vectors\n",
    "        self.prototypes = np.zeros((num_classes, feature_dim))\n",
    "        # Count of samples per class for prototype updating\n",
    "        self.class_counts = np.zeros(num_classes)\n",
    "    \n",
    "    def predict_probabilities(self, features):\n",
    "        \"\"\"\n",
    "        Computes normalized cosine similarity scores as probabilities.\n",
    "\n",
    "        Args:\n",
    "            features (numpy.ndarray): Feature vectors.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Probability-like scores for each class.\n",
    "        \"\"\"\n",
    "        similarities = cosine_similarity(features, self.prototypes)\n",
    "        # Normalize similarities to range [0, 1] to act as probabilities\n",
    "        exp_similarities = np.exp(similarities)  # Exponentiate to ensure positivity\n",
    "        probabilities = exp_similarities / np.sum(exp_similarities, axis=1, keepdims=True)\n",
    "        return probabilities\n",
    "\n",
    "    def initialize_prototypes(self, features, labels):\n",
    "        \"\"\"\n",
    "        Initializes class prototypes based on the initial labeled data.\n",
    "\n",
    "        Args:\n",
    "            features (numpy.ndarray): Feature vectors.\n",
    "            labels (numpy.ndarray): Corresponding labels.\n",
    "        \"\"\"\n",
    "        for class_idx in range(self.num_classes):\n",
    "            class_features = features[labels == class_idx]\n",
    "            if len(class_features) > 0:\n",
    "                self.prototypes[class_idx] = np.mean(class_features, axis=0)\n",
    "                self.prototypes[class_idx] /= np.linalg.norm(self.prototypes[class_idx])  # Normalize\n",
    "                self.class_counts[class_idx] = len(class_features)\n",
    "            else:\n",
    "                # Handle classes with no initial samples\n",
    "                self.prototypes[class_idx] = np.random.randn(self.feature_dim)\n",
    "                self.prototypes[class_idx] /= np.linalg.norm(self.prototypes[class_idx])\n",
    "                self.class_counts[class_idx] = 1\n",
    "\n",
    "    def predict(self, features):\n",
    "        \"\"\"\n",
    "        Predicts class labels for given feature vectors.\n",
    "\n",
    "        Args:\n",
    "            features (numpy.ndarray): Feature vectors.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Predicted class labels.\n",
    "        \"\"\"\n",
    "        similarities = cosine_similarity(features, self.prototypes)\n",
    "        return np.argmax(similarities, axis=1)\n",
    "\n",
    "    def update_prototypes(self, features, labels):\n",
    "        \"\"\"\n",
    "        Updates class prototypes with new labeled data.\n",
    "\n",
    "        Args:\n",
    "            features (numpy.ndarray): Newly labeled feature vectors.\n",
    "            labels (numpy.ndarray): Corresponding labels.\n",
    "        \"\"\"\n",
    "        for class_idx in range(self.num_classes):\n",
    "            class_features = features[labels == class_idx]\n",
    "            if len(class_features) == 0:\n",
    "                continue  # No new data for this class\n",
    "            # Compute mean of new features\n",
    "            new_mean = np.mean(class_features, axis=0)\n",
    "            new_mean /= np.linalg.norm(new_mean)\n",
    "            # Update prototype using running average\n",
    "            total_count = self.class_counts[class_idx] + len(class_features)\n",
    "            self.prototypes[class_idx] = (self.prototypes[class_idx] * self.class_counts[class_idx] + new_mean * len(class_features)) / total_count\n",
    "            self.prototypes[class_idx] /= np.linalg.norm(self.prototypes[class_idx])  # Normalize\n",
    "            self.class_counts[class_idx] = total_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FSwgAIEBDAGc",
    "outputId": "13051c72-dc67-40bb-fe11-aec3f83c5a63"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2379473238.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D1 = torch.load('1_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2379473238.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D2 = torch.load('2_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2379473238.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D3 = torch.load('3_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2379473238.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D4 = torch.load('4_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2379473238.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D5 = torch.load('5_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2379473238.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D6 = torch.load('6_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2379473238.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D7 = torch.load('7_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2379473238.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D8 = torch.load('8_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2379473238.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D9 = torch.load('9_train_data.tar.pth')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2379473238.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D10 = torch.load('10_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2379473238.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D11 = torch.load('11_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2379473238.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D12 = torch.load('12_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2379473238.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D13 = torch.load('13_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2379473238.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D14 = torch.load('14_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2379473238.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D15 = torch.load('15_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2379473238.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D16 = torch.load('16_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2379473238.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D17 = torch.load('17_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2379473238.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D18 = torch.load('18_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2379473238.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D19 = torch.load('19_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2379473238.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D20 = torch.load('20_train_data.tar.pth')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "D1 = torch.load('1_train_data.tar.pth')\n",
    "#print(t.keys()) # it will print data and targets\n",
    "#data, targets = t['data'], t['targets'] # both numpy.ndarray\n",
    "D2 = torch.load('2_train_data.tar.pth')\n",
    "D3 = torch.load('3_train_data.tar.pth')\n",
    "D4 = torch.load('4_train_data.tar.pth')\n",
    "D5 = torch.load('5_train_data.tar.pth')\n",
    "D6 = torch.load('6_train_data.tar.pth')\n",
    "D7 = torch.load('7_train_data.tar.pth')\n",
    "D8 = torch.load('8_train_data.tar.pth')\n",
    "D9 = torch.load('9_train_data.tar.pth')\n",
    "D10 = torch.load('10_train_data.tar.pth')\n",
    "D11 = torch.load('11_train_data.tar.pth')\n",
    "D12 = torch.load('12_train_data.tar.pth')\n",
    "D13 = torch.load('13_train_data.tar.pth')\n",
    "D14 = torch.load('14_train_data.tar.pth')\n",
    "D15 = torch.load('15_train_data.tar.pth')\n",
    "D16 = torch.load('16_train_data.tar.pth')\n",
    "D17 = torch.load('17_train_data.tar.pth')\n",
    "D18 = torch.load('18_train_data.tar.pth')\n",
    "D19 = torch.load('19_train_data.tar.pth')\n",
    "D20 = torch.load('20_train_data.tar.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e9AAVkxD_SL",
    "outputId": "febc90f7-ba82-4b3d-ddb3-c59d8c54df90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\3206332515.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  T1 = torch.load('1_eval_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\3206332515.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  T2 = torch.load('2_eval_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\3206332515.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  T3 = torch.load('3_eval_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\3206332515.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  T4 = torch.load('4_eval_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\3206332515.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  T5 = torch.load('5_eval_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\3206332515.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  T6 = torch.load('6_eval_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\3206332515.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  T7 = torch.load('7_eval_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\3206332515.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  T8 = torch.load('8_eval_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\3206332515.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  T9 = torch.load('9_eval_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\3206332515.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  T10 = torch.load('10_eval_data.tar.pth')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\3206332515.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  T11 = torch.load('11_eval_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\3206332515.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  T12 = torch.load('12_eval_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\3206332515.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  T13 = torch.load('13_eval_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\3206332515.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  T14 = torch.load('14_eval_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\3206332515.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  T15 = torch.load('15_eval_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\3206332515.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  T16 = torch.load('16_eval_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\3206332515.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  T17 = torch.load('17_eval_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\3206332515.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  T18 = torch.load('18_eval_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\3206332515.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  T19 = torch.load('19_eval_data.tar.pth')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\3206332515.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  T20 = torch.load('20_eval_data.tar.pth')\n"
     ]
    }
   ],
   "source": [
    "T1 = torch.load('1_eval_data.tar.pth')\n",
    "T2 = torch.load('2_eval_data.tar.pth')\n",
    "T3 = torch.load('3_eval_data.tar.pth')\n",
    "T4 = torch.load('4_eval_data.tar.pth')\n",
    "T5 = torch.load('5_eval_data.tar.pth')\n",
    "T6 = torch.load('6_eval_data.tar.pth')\n",
    "T7 = torch.load('7_eval_data.tar.pth')\n",
    "T8 = torch.load('8_eval_data.tar.pth')\n",
    "T9 = torch.load('9_eval_data.tar.pth')\n",
    "T10 = torch.load('10_eval_data.tar.pth')\n",
    "T11 = torch.load('11_eval_data.tar.pth')\n",
    "T12 = torch.load('12_eval_data.tar.pth')\n",
    "T13 = torch.load('13_eval_data.tar.pth')\n",
    "T14 = torch.load('14_eval_data.tar.pth')\n",
    "T15 = torch.load('15_eval_data.tar.pth')\n",
    "T16 = torch.load('16_eval_data.tar.pth')\n",
    "T17 = torch.load('17_eval_data.tar.pth')\n",
    "T18 = torch.load('18_eval_data.tar.pth')\n",
    "T19 = torch.load('19_eval_data.tar.pth')\n",
    "T20 = torch.load('20_eval_data.tar.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ao__fDwREpJK"
   },
   "outputs": [],
   "source": [
    "Testsets = []\n",
    "data = T1['data']  # Shape: (num_samples, 32, 32, 3)\n",
    "target = T1['targets']  # Shape: (num_samples,)\n",
    "Testsets.append({'data': data, 'target': target})\n",
    "data = T2['data']\n",
    "target = T2['targets']\n",
    "Testsets.append({'data': data, 'target': target})\n",
    "data = T3['data']\n",
    "target = T3['targets']\n",
    "Testsets.append({'data': data, 'target': target})\n",
    "data = T4['data']\n",
    "target = T4['targets']\n",
    "Testsets.append({'data': data, 'target': target})\n",
    "data = T5['data']\n",
    "target = T5['targets']\n",
    "Testsets.append({'data': data, 'target': target})\n",
    "data = T6['data']\n",
    "target = T6['targets']\n",
    "Testsets.append({'data': data, 'target': target})\n",
    "data = T7['data']\n",
    "target = T7['targets']\n",
    "Testsets.append({'data': data, 'target': target})\n",
    "data = T8['data']\n",
    "target = T8['targets']\n",
    "Testsets.append({'data': data, 'target': target})\n",
    "data = T9['data']\n",
    "target = T9['targets']\n",
    "Testsets.append({'data': data, 'target': target})\n",
    "data = T10['data']\n",
    "target = T10['targets']\n",
    "Testsets.append({'data': data, 'target': target})\n",
    "data = T11['data']\n",
    "target = T11['targets']\n",
    "Testsets.append({'data': data, 'target': target})\n",
    "data = T12['data']\n",
    "target = T12['targets']\n",
    "Testsets.append({'data': data, 'target': target})\n",
    "data = T13['data']\n",
    "target = T13['targets']\n",
    "Testsets.append({'data': data, 'target': target})\n",
    "data = T14['data']\n",
    "target = T14['targets']\n",
    "Testsets.append({'data': data, 'target': target})\n",
    "data = T15['data']\n",
    "target = T15['targets']\n",
    "Testsets.append({'data': data, 'target': target})\n",
    "data = T16['data']\n",
    "target = T16['targets']\n",
    "Testsets.append({'data': data, 'target': target})\n",
    "data = T17['data']\n",
    "target = T17['targets']\n",
    "Testsets.append({'data': data, 'target': target})\n",
    "data = T18['data']\n",
    "target = T18['targets']\n",
    "Testsets.append({'data': data, 'target': target})\n",
    "data = T19['data']\n",
    "target = T19['targets']\n",
    "Testsets.append({'data': data, 'target': target})\n",
    "data = T20['data']\n",
    "target = T20['targets']\n",
    "Testsets.append({'data': data, 'target': target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cyz6xtzhDdVO"
   },
   "outputs": [],
   "source": [
    "datasets = []\n",
    "data = D1['data']  # Shape: (num_samples, 32, 32, 3)\n",
    "target = D1['targets']  # Shape: (num_samples,)\n",
    "datasets.append({'data': data, 'target': target})\n",
    "\n",
    "data = D2['data']  # Shape: (num_samples, 32, 32,)\n",
    "datasets.append({'data': data})\n",
    "data = D3['data']\n",
    "datasets.append({'data': data})\n",
    "data = D4['data']\n",
    "datasets.append({'data': data})\n",
    "data = D5['data']\n",
    "datasets.append({'data': data})\n",
    "data = D6['data']\n",
    "datasets.append({'data': data})\n",
    "data = D7['data']\n",
    "datasets.append({'data': data})\n",
    "data = D8['data']\n",
    "datasets.append({'data': data})\n",
    "data = D9['data']\n",
    "datasets.append({'data': data})\n",
    "data = D10['data']\n",
    "datasets.append({'data': data})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1dCp3hiiJSNq"
   },
   "outputs": [],
   "source": [
    "for i in range(10):  # Only first 10 datasets as per the problem\n",
    "    #print(f\"Extracting features for D{i+1}...\")\n",
    "    data = datasets[i]['data']\n",
    "    #feature_extractor = initialize_custom_cnn()\n",
    "    features = extract_features(data)\n",
    "    datasets[i]['features'] = features\n",
    "    if i == 0:\n",
    "        labels = datasets[i]['target']\n",
    "        datasets[i]['labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "wIhJuGgnF0zl"
   },
   "outputs": [],
   "source": [
    "for i in range(20):  # Only first 10 datasets as per the problem\n",
    "    #print(f\"Extracting features for D{i+1}...\")\n",
    "    data = Testsets[i]['data']\n",
    "    #feature_extractor = initialize_feature_extractor()\n",
    "    #features = extract_features(data,batch_size=128)\n",
    "    #feature_extractor = initialize_custom_cnn()\n",
    "    features = extract_features(data)\n",
    "    #features = extract_features(data)\n",
    "    Testsets[i]['features'] = features\n",
    "    labels = Testsets[i]['target']\n",
    "    Testsets[i]['labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "RMhqxFwfD7i_"
   },
   "outputs": [],
   "source": [
    "num_classes = 10  # CIFAR-10 has 10 classes\n",
    "feature_dim = 1280  # ResNet50 with pooling='avg' outputs 2048-dimensional vectors\n",
    "\n",
    "# Initialize LwP classifier\n",
    "lwpc = LwPClassifier(num_classes=num_classes, feature_dim=feature_dim)\n",
    "#lwpc = SigmoidKernelLwPClassifier(num_classes=10, feature_dim=1280, alpha=1.0, c=0.05)\n",
    "\n",
    "# Initialize prototypes using D1\n",
    "lwpc.initialize_prototypes(datasets[0]['features'], datasets[0]['labels'])\n",
    "\n",
    "models = []\n",
    "models.append(lwpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b2wlvP-hLavI",
    "outputId": "bc3cb738-516d-44de-84c1-b426061f86ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "testing for 1th model\n",
      "#########################\n",
      "Accuracy on T1: 0.7504\n",
      "#########################\n",
      "testing for 2th model\n",
      "#########################\n",
      "Accuracy on T1: 0.7504\n",
      "Accuracy on T2: 0.7488\n",
      "#########################\n",
      "testing for 3th model\n",
      "#########################\n",
      "Accuracy on T1: 0.7476\n",
      "Accuracy on T2: 0.7484\n",
      "Accuracy on T3: 0.7304\n",
      "#########################\n",
      "testing for 4th model\n",
      "#########################\n",
      "Accuracy on T1: 0.7484\n",
      "Accuracy on T2: 0.748\n",
      "Accuracy on T3: 0.7304\n",
      "Accuracy on T4: 0.7468\n",
      "#########################\n",
      "testing for 5th model\n",
      "#########################\n",
      "Accuracy on T1: 0.7488\n",
      "Accuracy on T2: 0.7476\n",
      "Accuracy on T3: 0.7292\n",
      "Accuracy on T4: 0.7468\n",
      "Accuracy on T5: 0.764\n",
      "#########################\n",
      "testing for 6th model\n",
      "#########################\n",
      "Accuracy on T1: 0.7472\n",
      "Accuracy on T2: 0.748\n",
      "Accuracy on T3: 0.7308\n",
      "Accuracy on T4: 0.7452\n",
      "Accuracy on T5: 0.7624\n",
      "Accuracy on T6: 0.7612\n",
      "#########################\n",
      "testing for 7th model\n",
      "#########################\n",
      "Accuracy on T1: 0.7468\n",
      "Accuracy on T2: 0.7472\n",
      "Accuracy on T3: 0.7304\n",
      "Accuracy on T4: 0.7456\n",
      "Accuracy on T5: 0.762\n",
      "Accuracy on T6: 0.76\n",
      "Accuracy on T7: 0.7328\n",
      "#########################\n",
      "testing for 8th model\n",
      "#########################\n",
      "Accuracy on T1: 0.7456\n",
      "Accuracy on T2: 0.7472\n",
      "Accuracy on T3: 0.7296\n",
      "Accuracy on T4: 0.7456\n",
      "Accuracy on T5: 0.7608\n",
      "Accuracy on T6: 0.7596\n",
      "Accuracy on T7: 0.7328\n",
      "Accuracy on T8: 0.742\n",
      "#########################\n",
      "testing for 9th model\n",
      "#########################\n",
      "Accuracy on T1: 0.7464\n",
      "Accuracy on T2: 0.7472\n",
      "Accuracy on T3: 0.728\n",
      "Accuracy on T4: 0.7448\n",
      "Accuracy on T5: 0.762\n",
      "Accuracy on T6: 0.7592\n",
      "Accuracy on T7: 0.7324\n",
      "Accuracy on T8: 0.7408\n",
      "Accuracy on T9: 0.7332\n",
      "#########################\n",
      "testing for 10th model\n",
      "#########################\n",
      "Accuracy on T1: 0.7464\n",
      "Accuracy on T2: 0.7476\n",
      "Accuracy on T3: 0.7292\n",
      "Accuracy on T4: 0.7448\n",
      "Accuracy on T5: 0.76\n",
      "Accuracy on T6: 0.7588\n",
      "Accuracy on T7: 0.7336\n",
      "Accuracy on T8: 0.7412\n",
      "Accuracy on T9: 0.7328\n",
      "Accuracy on T10: 0.7492\n"
     ]
    }
   ],
   "source": [
    "# Initialize prototypes using D1\n",
    "#lwpc = LwPClassifier(num_classes=num_classes, feature_dim=feature_dim)\n",
    "#lwpc.initialize_prototypes(datasets[0]['features'], datasets[0]['labels'])\n",
    "\n",
    "for i in range(0, 10):  # Indices 1 to 9 correspond to D2 to D10\n",
    "    print(\"#########################\")\n",
    "    print(f\"testing for {i+1}th model\")\n",
    "    print(\"#########################\")\n",
    "    \n",
    "    if i!=0 :\n",
    "        current_features = datasets[i]['features']\n",
    "        predicted_labels = lwpc.predict(current_features)\n",
    "        datasets[i]['predicted_labels'] = predicted_labels\n",
    "        lwpc.update_prototypes(current_features, predicted_labels)\n",
    "        models.append(lwpc)\n",
    "        \n",
    "    for j in range(0,i+1):\n",
    "           feature = Testsets[j]['features']\n",
    "           label = Testsets[j]['labels']\n",
    "\n",
    "           predictions = lwpc.predict(feature)\n",
    "           accuracy = np.mean(predictions == label)\n",
    "           print(f\"Accuracy on T{j+1}: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NZzzWrJTeXsz",
    "outputId": "760ee4fc-b9fb-4ea6-a9ba-a3ca936df559"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2243097193.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D11 = torch.load('11_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2243097193.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D12 = torch.load('12_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2243097193.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D13 = torch.load('13_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2243097193.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D14 = torch.load('14_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2243097193.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D15 = torch.load('15_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2243097193.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D16 = torch.load('16_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2243097193.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D17 = torch.load('17_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2243097193.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D18 = torch.load('18_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2243097193.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D19 = torch.load('19_train_data.tar.pth')\n",
      "C:\\Users\\AVNI MAHESHWARI\\AppData\\Local\\Temp\\ipykernel_18120\\2243097193.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D20 = torch.load('20_train_data.tar.pth')\n"
     ]
    }
   ],
   "source": [
    "D11 = torch.load('11_train_data.tar.pth')\n",
    "D12 = torch.load('12_train_data.tar.pth')\n",
    "D13 = torch.load('13_train_data.tar.pth')\n",
    "D14 = torch.load('14_train_data.tar.pth')\n",
    "D15 = torch.load('15_train_data.tar.pth')\n",
    "D16 = torch.load('16_train_data.tar.pth')\n",
    "D17 = torch.load('17_train_data.tar.pth')\n",
    "D18 = torch.load('18_train_data.tar.pth')\n",
    "D19 = torch.load('19_train_data.tar.pth')\n",
    "D20 = torch.load('20_train_data.tar.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "moqYVDF8fy2d"
   },
   "outputs": [],
   "source": [
    "data = D11['data']  # Shape: (num_samples, 32, 32,)\n",
    "datasets.append({'data': data})\n",
    "data = D12['data']\n",
    "datasets.append({'data': data})\n",
    "data = D13['data']\n",
    "datasets.append({'data': data})\n",
    "data = D14['data']\n",
    "datasets.append({'data': data})\n",
    "data = D15['data']\n",
    "datasets.append({'data': data})\n",
    "data = D16['data']\n",
    "datasets.append({'data': data})\n",
    "data = D17['data']\n",
    "datasets.append({'data': data})\n",
    "data = D18['data']\n",
    "datasets.append({'data': data})\n",
    "data = D19['data']\n",
    "datasets.append({'data': data})\n",
    "data = D20['data']\n",
    "datasets.append({'data': data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "pr6q9tRKgPWF"
   },
   "outputs": [],
   "source": [
    "for i in range(10,20):  # Only first 10 datasets as per the problem\n",
    "    #print(f\"Extracting features for D{i+1}...\")\n",
    "    data = datasets[i]['data']\n",
    "    features = extract_features(data)\n",
    "    datasets[i]['features'] = features\n",
    "    if i == 0:\n",
    "        labels = datasets[i]['target']\n",
    "        datasets[i]['labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating model for Dataset D11...\n",
      "Accuracy on T1: 0.7464\n",
      "Accuracy on T2: 0.7476\n",
      "Accuracy on T3: 0.7292\n",
      "Accuracy on T4: 0.7448\n",
      "Accuracy on T5: 0.76\n",
      "Accuracy on T6: 0.7588\n",
      "Accuracy on T7: 0.7336\n",
      "Accuracy on T8: 0.7412\n",
      "Accuracy on T9: 0.7328\n",
      "Accuracy on T10: 0.7492\n",
      "Accuracy on T11: 0.5732\n",
      "Updating model for Dataset D12...\n",
      "Accuracy on T1: 0.7464\n",
      "Accuracy on T2: 0.7476\n",
      "Accuracy on T3: 0.7292\n",
      "Accuracy on T4: 0.7448\n",
      "Accuracy on T5: 0.76\n",
      "Accuracy on T6: 0.7588\n",
      "Accuracy on T7: 0.7336\n",
      "Accuracy on T8: 0.7412\n",
      "Accuracy on T9: 0.7328\n",
      "Accuracy on T10: 0.7492\n",
      "Accuracy on T11: 0.5732\n",
      "Accuracy on T12: 0.4976\n",
      "Updating model for Dataset D13...\n",
      "Accuracy on T1: 0.7464\n",
      "Accuracy on T2: 0.7476\n",
      "Accuracy on T3: 0.7292\n",
      "Accuracy on T4: 0.7448\n",
      "Accuracy on T5: 0.76\n",
      "Accuracy on T6: 0.7588\n",
      "Accuracy on T7: 0.7336\n",
      "Accuracy on T8: 0.7412\n",
      "Accuracy on T9: 0.7328\n",
      "Accuracy on T10: 0.7492\n",
      "Accuracy on T11: 0.5732\n",
      "Accuracy on T12: 0.4976\n",
      "Accuracy on T13: 0.6756\n",
      "Updating model for Dataset D14...\n",
      "Accuracy on T1: 0.7464\n",
      "Accuracy on T2: 0.7476\n",
      "Accuracy on T3: 0.7292\n",
      "Accuracy on T4: 0.7448\n",
      "Accuracy on T5: 0.76\n",
      "Accuracy on T6: 0.7588\n",
      "Accuracy on T7: 0.7336\n",
      "Accuracy on T8: 0.7412\n",
      "Accuracy on T9: 0.7328\n",
      "Accuracy on T10: 0.7492\n",
      "Accuracy on T11: 0.5732\n",
      "Accuracy on T12: 0.4976\n",
      "Accuracy on T13: 0.6756\n",
      "Accuracy on T14: 0.6264\n",
      "Updating model for Dataset D15...\n",
      "Accuracy on T1: 0.7464\n",
      "Accuracy on T2: 0.7476\n",
      "Accuracy on T3: 0.7292\n",
      "Accuracy on T4: 0.7448\n",
      "Accuracy on T5: 0.76\n",
      "Accuracy on T6: 0.7588\n",
      "Accuracy on T7: 0.7336\n",
      "Accuracy on T8: 0.7412\n",
      "Accuracy on T9: 0.7328\n",
      "Accuracy on T10: 0.7492\n",
      "Accuracy on T11: 0.5732\n",
      "Accuracy on T12: 0.4976\n",
      "Accuracy on T13: 0.6756\n",
      "Accuracy on T14: 0.6264\n",
      "Accuracy on T15: 0.75\n",
      "Updating model for Dataset D16...\n",
      "Accuracy on T1: 0.7464\n",
      "Accuracy on T2: 0.7476\n",
      "Accuracy on T3: 0.7292\n",
      "Accuracy on T4: 0.7448\n",
      "Accuracy on T5: 0.76\n",
      "Accuracy on T6: 0.7588\n",
      "Accuracy on T7: 0.7336\n",
      "Accuracy on T8: 0.7412\n",
      "Accuracy on T9: 0.7328\n",
      "Accuracy on T10: 0.7492\n",
      "Accuracy on T11: 0.5732\n",
      "Accuracy on T12: 0.4976\n",
      "Accuracy on T13: 0.6756\n",
      "Accuracy on T14: 0.6264\n",
      "Accuracy on T15: 0.75\n",
      "Accuracy on T16: 0.5956\n",
      "Updating model for Dataset D17...\n",
      "Accuracy on T1: 0.7464\n",
      "Accuracy on T2: 0.7476\n",
      "Accuracy on T3: 0.7292\n",
      "Accuracy on T4: 0.7448\n",
      "Accuracy on T5: 0.76\n",
      "Accuracy on T6: 0.7588\n",
      "Accuracy on T7: 0.7336\n",
      "Accuracy on T8: 0.7412\n",
      "Accuracy on T9: 0.7328\n",
      "Accuracy on T10: 0.7492\n",
      "Accuracy on T11: 0.5732\n",
      "Accuracy on T12: 0.4976\n",
      "Accuracy on T13: 0.6756\n",
      "Accuracy on T14: 0.6264\n",
      "Accuracy on T15: 0.75\n",
      "Accuracy on T16: 0.5956\n",
      "Accuracy on T17: 0.6128\n",
      "Updating model for Dataset D18...\n",
      "Accuracy on T1: 0.7464\n",
      "Accuracy on T2: 0.7476\n",
      "Accuracy on T3: 0.7292\n",
      "Accuracy on T4: 0.7448\n",
      "Accuracy on T5: 0.76\n",
      "Accuracy on T6: 0.7588\n",
      "Accuracy on T7: 0.7336\n",
      "Accuracy on T8: 0.7412\n",
      "Accuracy on T9: 0.7328\n",
      "Accuracy on T10: 0.7492\n",
      "Accuracy on T11: 0.5732\n",
      "Accuracy on T12: 0.4976\n",
      "Accuracy on T13: 0.6756\n",
      "Accuracy on T14: 0.6264\n",
      "Accuracy on T15: 0.75\n",
      "Accuracy on T16: 0.5956\n",
      "Accuracy on T17: 0.6128\n",
      "Accuracy on T18: 0.6756\n",
      "Updating model for Dataset D19...\n",
      "Accuracy on T1: 0.7464\n",
      "Accuracy on T2: 0.7476\n",
      "Accuracy on T3: 0.7292\n",
      "Accuracy on T4: 0.7448\n",
      "Accuracy on T5: 0.76\n",
      "Accuracy on T6: 0.7588\n",
      "Accuracy on T7: 0.7336\n",
      "Accuracy on T8: 0.7412\n",
      "Accuracy on T9: 0.7328\n",
      "Accuracy on T10: 0.7492\n",
      "Accuracy on T11: 0.5732\n",
      "Accuracy on T12: 0.4976\n",
      "Accuracy on T13: 0.6756\n",
      "Accuracy on T14: 0.6264\n",
      "Accuracy on T15: 0.75\n",
      "Accuracy on T16: 0.5956\n",
      "Accuracy on T17: 0.6128\n",
      "Accuracy on T18: 0.6756\n",
      "Accuracy on T19: 0.504\n",
      "Updating model for Dataset D20...\n",
      "Accuracy on T1: 0.7464\n",
      "Accuracy on T2: 0.7476\n",
      "Accuracy on T3: 0.7292\n",
      "Accuracy on T4: 0.7448\n",
      "Accuracy on T5: 0.76\n",
      "Accuracy on T6: 0.7588\n",
      "Accuracy on T7: 0.7336\n",
      "Accuracy on T8: 0.7412\n",
      "Accuracy on T9: 0.7328\n",
      "Accuracy on T10: 0.7492\n",
      "Accuracy on T11: 0.5732\n",
      "Accuracy on T12: 0.4976\n",
      "Accuracy on T13: 0.6756\n",
      "Accuracy on T14: 0.6264\n",
      "Accuracy on T15: 0.75\n",
      "Accuracy on T16: 0.5956\n",
      "Accuracy on T17: 0.6128\n",
      "Accuracy on T18: 0.6756\n",
      "Accuracy on T19: 0.504\n",
      "Accuracy on T20: 0.7172\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Updated pseudo-labeling mechanism\n",
    "def pseudo_label_with_confidence(model, features, confidence_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Generates pseudo-labels for features using the LwPClassifier.\n",
    "    Only returns samples with a confidence above the threshold.\n",
    "\n",
    "    Args:\n",
    "        model (LwPClassifier): The classifier.\n",
    "        features (numpy.ndarray): Feature vectors.\n",
    "        confidence_threshold (float): Minimum confidence for pseudo-labeling.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray, numpy.ndarray: Confident features and their pseudo-labels.\n",
    "    \"\"\"\n",
    "    # Get probability-like scores\n",
    "    probabilities = model.predict_probabilities(features)\n",
    "\n",
    "    # Compute confidences and pseudo-labels\n",
    "    confidences = np.max(probabilities, axis=1)\n",
    "    pseudo_labels = np.argmax(probabilities, axis=1)\n",
    "\n",
    "    # Filter samples with confidence above the threshold\n",
    "    mask = confidences >= confidence_threshold\n",
    "    confident_features = features[mask]\n",
    "    confident_labels = pseudo_labels[mask]\n",
    "    return confident_features, confident_labels\n",
    "\n",
    "# Mixup augmentation function\n",
    "def mixup(x1, x2, y1, y2, alpha=0.4):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    x_mix = lam * x1 + (1 - lam) * x2\n",
    "    y_mix = lam * y1 + (1 - lam) * y2\n",
    "    return x_mix, y_mix\n",
    "\n",
    "# Contrastive alignment loss\n",
    "def prototype_alignment_loss(features, prototypes, labels):\n",
    "    similarities = torch.matmul(features, prototypes.T)\n",
    "    loss = torch.nn.CrossEntropyLoss()(similarities, labels)\n",
    "    return loss\n",
    "\n",
    "# Update process with improved mechanisms\n",
    "for i in range(10, 20):  # Task 1.2 updates for D11 to D20\n",
    "    print(f\"Updating model for Dataset D{i+1}...\")\n",
    "\n",
    "    # Extract features and pseudo-labels with confidence filtering\n",
    "    current_features = datasets[i]['features']\n",
    "    confident_features, pseudo_labels = pseudo_label_with_confidence(lwpc, current_features)\n",
    "\n",
    "    # Apply Random Mixup\n",
    "    if confident_features.shape[0] > 1:  # Ensure at least two samples for mixup\n",
    "        idx = np.random.permutation(confident_features.shape[0])  # Use numpy for shuffling indices\n",
    "        mixed_features, mixed_labels = mixup(\n",
    "            confident_features, confident_features[idx],\n",
    "            pseudo_labels, pseudo_labels[idx]\n",
    "        )\n",
    "    else:\n",
    "        mixed_features, mixed_labels = confident_features, pseudo_labels\n",
    "\n",
    "    # Update prototypes using contrastive alignment\n",
    "    lwpc.update_prototypes(mixed_features, mixed_labels)\n",
    "    models.append(lwpc)\n",
    "\n",
    "    # Evaluate the updated model\n",
    "    for j in range(0, i + 1):  # Test on all seen datasets\n",
    "        features = Testsets[j]['features']\n",
    "        labels = Testsets[j]['labels']\n",
    "        predictions = lwpc.predict(features)\n",
    "        accuracy = np.mean(predictions == labels)\n",
    "        print(f\"Accuracy on T{j+1}: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
